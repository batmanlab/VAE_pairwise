{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import VAE_pairwise\n",
    "\n",
    "import chairs_dataset_CV\n",
    "import cars_dataset_CV\n",
    "import Yale_dataset_CV\n",
    "import MNIST_dataset_CV\n",
    "import fashionMNIST_dataset_CV\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "Dataset = MNIST_dataset_CV.Dataset\n",
    "\n",
    "\n",
    "model = VAE_pairwise.VAE_pairwise(Dataset, K = 1, \n",
    "                         alpha = 1., gamma = 1., C1 = 100, C2 = .2, n_conv = 4, n_fc = 1, n_channels = 128, \n",
    "                         d_latent = 128, beta1 = 1., beta2 = 1., sigma = 45., \n",
    "                         device = device, training_step = 10000, annealing_step= 5000).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 1\n",
      "training_step 10000\n",
      "0 0 38.77859878540039 \t 38.77859878540039\n",
      "Classifier Loss 539.1434936523438 gamma=4.539787187241018e-05 C1 = 100 C2 = 0.2\n",
      "0 100 11.483339323855862 \t 9.869829177856445\n",
      "Classifier Loss 115.77569580078125 gamma=5.5448515922762454e-05 C1 = 100 C2 = 0.2\n",
      "0 200 9.529896011399986 \t 9.57911491394043\n",
      "Classifier Loss 164.95263671875 gamma=6.772412598365918e-05 C1 = 100 C2 = 0.2\n",
      "0 300 8.639454520025918 \t 3.7018826007843018\n",
      "Classifier Loss 149.8786163330078 gamma=8.271725528175011e-05 C1 = 100 C2 = 0.2\n",
      "0 400 8.224395261441085 \t 7.586039066314697\n",
      "Classifier Loss 159.4984588623047 gamma=0.00010102921805810183 C1 = 100 C2 = 0.2\n",
      "0 500 7.827635902606561 \t 6.96265983581543\n",
      "Classifier Loss 129.66188049316406 gamma=0.00012339458044152707 C1 = 100 C2 = 0.2\n",
      "0 600 7.528561564729535 \t 5.229007244110107\n",
      "Classifier Loss 128.64271545410156 gamma=0.00015071032976265997 C1 = 100 C2 = 0.2\n",
      "0 700 7.331725950077835 \t 6.632379531860352\n",
      "Classifier Loss 170.3145751953125 gamma=0.00018407183233648539 C1 = 100 C2 = 0.2\n",
      "0 800 7.1429817224114425 \t 4.074917316436768\n",
      "Classifier Loss 83.39987182617188 gamma=0.00022481686028186232 C1 = 100 C2 = 0.2\n",
      "0 900 6.959234678784962 \t 4.496505260467529\n",
      "Classifier Loss 79.76217651367188 gamma=0.00027457819669507444 C1 = 100 C2 = 0.2\n",
      "0 1000 6.853967414631115 \t 6.686285972595215\n",
      "Classifier Loss 116.59722900390625 gamma=0.00033535013790242374 C1 = 100 C2 = 0.2\n",
      "0 1100 6.724866878975531 \t 4.516053199768066\n",
      "Classifier Loss 54.94038009643555 gamma=0.0004095670592505485 C1 = 100 C2 = 0.2\n",
      "0 1200 6.652942143907952 \t 7.302754878997803\n",
      "Classifier Loss 184.6826171875 gamma=0.0005002011894248426 C1 = 100 C2 = 0.2\n",
      "0 1300 6.560370815249245 \t 4.69539737701416\n",
      "Classifier Loss 79.12411499023438 gamma=0.0006108792731538415 C1 = 100 C2 = 0.2\n",
      "0 1400 6.51767947127528 \t 5.391951560974121\n",
      "Classifier Loss 110.56645202636719 gamma=0.0007460289634764194 C1 = 100 C2 = 0.2\n",
      "0 1500 6.461357147831825 \t 4.583305358886719\n",
      "Classifier Loss 124.0643310546875 gamma=0.0009110511746257544 C1 = 100 C2 = 0.2\n",
      "0 1600 6.416253985054116 \t 5.029784202575684\n",
      "Classifier Loss 105.70513916015625 gamma=0.0011125358287245035 C1 = 100 C2 = 0.2\n",
      "0 1700 6.370828707171916 \t 6.339644432067871\n",
      "Classifier Loss 146.82553100585938 gamma=0.0013585201231762767 C1 = 100 C2 = 0.2\n",
      "0 1800 6.338118953482433 \t 4.004086494445801\n",
      "Classifier Loss 32.32579040527344 gamma=0.0016588008729740977 C1 = 100 C2 = 0.2\n"
     ]
    }
   ],
   "source": [
    "model.train_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-29cf5682da2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                          \u001b[0md_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m45.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                          device = device, training_step = 10000, annealing_step= 5000).to(device)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = VAE_pairwise.VAE_pairwise(Dataset, K = 1, \n",
    "                         alpha = 1., gamma = 1., C1 = 100, C2 = .2, n_conv = 4, n_fc = 1, n_channels = 128, \n",
    "                         d_latent = 128, beta1 = 1., beta2 = 1., sigma = 45., \n",
    "                         device = device, training_step = 10000, annealing_step= 5000).to(device)\n",
    "model.load_state_dict(torch.load(\"./model\"))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
